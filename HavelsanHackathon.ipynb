{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc39b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "from operator import add\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24dfae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords=['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki',\n",
    "           'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da',\n",
    "           'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her',\n",
    "           'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden',\n",
    "           'nerde', 'nerede', 'nereye', 'niçin',\n",
    "           'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a477dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('health.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "t_health_list = text.split('\\n')\n",
    "f = open('economics.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "t_economics_list = text.split('\\n')\n",
    "f = open('life.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "t_life_list = text.split('\\n')\n",
    "f = open('sports.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "t_sports_list = text.split('\\n')\n",
    "f = open('technology.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "t_technology_list = text.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a04bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list=t_health_list+t_economics_list+t_life_list+t_sports_list+t_technology_list\n",
    "sayilar=['0','1','2','3','4','5','6','7','8','9','w','x']\n",
    "corpus = []\n",
    "for cumle in full_list:\n",
    "    cumle=cumle.lower()\n",
    "    cumle=cumle.split()\n",
    "    for element in stopWords:\n",
    "        if element in cumle:\n",
    "            cumle.remove(element)\n",
    "    for wordS in cumle:\n",
    "        for sayi in sayilar:\n",
    "            if sayi in wordS:\n",
    "                cumle.remove(wordS)\n",
    "                break\n",
    "    corpus.append(cumle)\n",
    "    corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c3a138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(corpus))\n",
    "label=[]\n",
    "words=[]\n",
    "for cumle in corpus:\n",
    "    if(cumle):\n",
    "        label.append(cumle[0])\n",
    "        words.append(cumle[1:])\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "word_lengths=[]\n",
    "for sent in words:\n",
    "    sent_words=[]\n",
    "    for word in sent:\n",
    "        sent_words.append(len(word))\n",
    "    word_lengths.append(mean(sent_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0c6539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.119221108913486\n"
     ]
    }
   ],
   "source": [
    "new_word=[]\n",
    "spec_char=[',','.','!',';',':','(',')','[',']','\\'','`','?','-','\\\"','’','•','“','/','”','@','‘']\n",
    "for sent in words:\n",
    "    new_sent=[]\n",
    "    for word in sent:\n",
    "        for harf in word:\n",
    "            if harf in spec_char:\n",
    "                if(harf=='\\''):\n",
    "                    try:\n",
    "                        word=word[:word.index('\\'')]\n",
    "                    except:\n",
    "                        word=word.replace(harf,'')\n",
    "                elif(harf=='’'):\n",
    "                    try:\n",
    "                        word=word[:word.index('’')]\n",
    "                    except:\n",
    "                        word=word.replace(harf,'')\n",
    "                elif(harf=='-'):\n",
    "                    try:\n",
    "                        word=word[:word.index('-')]\n",
    "                    except:\n",
    "                        word=word.replace(harf,'')\n",
    "                else:\n",
    "                    word=word.replace(harf,'')\n",
    "        if(len(word)<8):\n",
    "            new_sent.append(word[0:len(word)]+'*'*(7-len(word)))\n",
    "        else:\n",
    "            new_sent.append(word[0:7])\n",
    "    new_word.append(new_sent)\n",
    "print(mean(word_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c422e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_word)\n",
    "vocab=[]\n",
    "for sent in new_word:\n",
    "    for wor in sent:\n",
    "        vocab.append(wor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79c6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_lengths=[230001, 220001,260001,210001, 2000001]\n",
    "\n",
    "txt_indexes=[230000,450001,710002,920003,1120004]\n",
    "\n",
    "health_txt=new_word[0:txt_indexes[0]]\n",
    "economy_txt=new_word[txt_indexes[0]+1:txt_indexes[1]]\n",
    "\n",
    "life_txt=new_word[txt_indexes[1]+1:txt_indexes[2]]\n",
    "\n",
    "sports_txt=new_word[txt_indexes[2]+1:txt_indexes[3]]\n",
    "technology_txt=new_word[txt_indexes[3]+1:txt_indexes[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8965a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs={}\n",
    "\n",
    "for word in vocab:\n",
    "            freqs[word] = [0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "for sentence in health_txt:\n",
    "    for word in sentence:\n",
    "        if word:\n",
    "            freqs[word][0]+=1\n",
    "            freqs[word][1] += 1\n",
    "\n",
    "for sentence in economy_txt:\n",
    "    for word in sentence:\n",
    "        if word:\n",
    "            freqs[word][0]+=1\n",
    "            freqs[word][2] += 1\n",
    "\n",
    "for sentence in life_txt:\n",
    "    for word in sentence:\n",
    "        if word:\n",
    "            freqs[word][0] +=1\n",
    "            freqs[word][3] += 1\n",
    "\n",
    "for sentence in sports_txt:\n",
    "    for word in sentence:\n",
    "        if word:\n",
    "            freqs[word][0]+=1\n",
    "            freqs[word][4] += 1\n",
    "\n",
    "for sentence in technology_txt:\n",
    "    for word in sentence:\n",
    "        if word:\n",
    "            freqs[word][0] += 1\n",
    "            freqs[word][5] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "615c2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full={}\n",
    "\n",
    "for i in range (0,230001):\n",
    "    y_full[i] = [0]\n",
    "    #y_health.append(0)\n",
    "for i in range (230001,230001+220001):\n",
    "     y_full[i] =[1]\n",
    "     #y_economy.append(1)\n",
    "for i in range (230001+220001,230001+220001+260001):\n",
    "     y_full[i]=[2]\n",
    "     #y_life.append(2)\n",
    "for i in range(230001+220001+260001,230001+220001+260001+210001):\n",
    "    y_full[i]=[3]\n",
    "    #y_sports.append(3)\n",
    "for i in range(230001+220001+260001+210001,230001+220001+260001+210001+200001):\n",
    "    y_full[i]=[4]\n",
    "    #y_technology.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc4c5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_matrix = {}\n",
    "sentences_indices = {}\n",
    "for sentence_number in range(0, len(corpus)):\n",
    "    sentence_matrix[sentence_number] = [0,0,0,0,0]\n",
    "\n",
    "\n",
    "sentence_number = 0\n",
    "for sent in new_word:\n",
    "    sentences_indices[sentence_number] = sent\n",
    "    for wor in sent:\n",
    "        sentence_matrix[sentence_number] = list(map(add,sentence_matrix[sentence_number],freqs[wor][1:len(freqs[wor])]))\n",
    "    sentence_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2442851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120005\n",
      "1120005\n"
     ]
    }
   ],
   "source": [
    "sentence_number+=1\n",
    "sentence_list = []\n",
    "print(len(sentence_matrix))\n",
    "print(len(y_full))\n",
    "for i in sentence_matrix.keys():\n",
    "    sentence_matrix[i] =sentence_matrix[i]+ y_full[i]\n",
    "    sentence_list.append(sentence_matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5863835",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = numpy.array(sentence_list)\n",
    "numpy.random.shuffle(temp)\n",
    "\n",
    "X = temp[:,:-1]\n",
    "y = temp[:,-1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16538476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LogisticRegression(multi_class='multinomial',solver='lbfgs',max_iter=1000)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# model=LogisticRegression(multi_class='multinomial')\n",
    "# model.fit(X_train,y_train)\n",
    "# predictions=model.predict(X_test)\n",
    "# trues=[predictions==Multinomy_test]\n",
    "# accuracy=np.sum(trues)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc5797d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5995196450015848"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "for i in range (0,len(y_pred)):\n",
    "    y_pred[i]=round(y_pred[i])\n",
    "trues=[y_pred==y_test]\n",
    "accuracy=np.sum(trues)/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f726d503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  1.82\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "print(\"Mean Squared Error: \", round(sm.mean_squared_error(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "997e5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_f1=f1_score(y_test,y_pred,average='weighted')\n",
    "# nb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = svm.SVC(kernel='polynomial', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "# linear_pred = linear.predict([42508, 47541, 47733, 28182, 69465])\n",
    "# accuracy_lin = linear.score(X_test, y_test)\n",
    "# print(linear_pred)\n",
    "# print(accuracy_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0961224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename='model_7_svm'\n",
    "# pickle.dump(linear,open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e0ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
